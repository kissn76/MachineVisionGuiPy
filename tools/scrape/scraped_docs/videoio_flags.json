{
    "VideoCaptureAPIs": {
        "description": "cv::VideoCapture API backends identifier.",
        "enumerator": {
            "CAP_ANY": "Auto detect == 0.",
            "CAP_VFW": "Video For Windows (obsolete, removed)",
            "CAP_V4L": "V4L/V4L2 capturing support.",
            "CAP_V4L2": "Same as CAP_V4L.",
            "CAP_FIREWIRE": "IEEE 1394 drivers.",
            "CAP_FIREWARE": "Same value as CAP_FIREWIRE.",
            "CAP_IEEE1394": "Same value as CAP_FIREWIRE.",
            "CAP_DC1394": "Same value as CAP_FIREWIRE.",
            "CAP_CMU1394": "Same value as CAP_FIREWIRE.",
            "CAP_QT": "QuickTime (obsolete, removed)",
            "CAP_UNICAP": "Unicap drivers (obsolete, removed)",
            "CAP_DSHOW": "DirectShow (via videoInput)",
            "CAP_PVAPI": "PvAPI, Prosilica GigE SDK.",
            "CAP_OPENNI": "OpenNI (for Kinect)",
            "CAP_OPENNI_ASUS": "OpenNI (for Asus Xtion)",
            "CAP_ANDROID": "Android - not used.",
            "CAP_XIAPI": "XIMEA Camera API.",
            "CAP_AVFOUNDATION": "AVFoundation framework for iOS (OS X Lion will have the same API)",
            "CAP_GIGANETIX": "Smartek Giganetix GigEVisionSDK.",
            "CAP_MSMF": "Microsoft Media Foundation (via videoInput)",
            "CAP_WINRT": "Microsoft Windows Runtime using Media Foundation.",
            "CAP_INTELPERC": "RealSense (former Intel Perceptual Computing SDK)",
            "CAP_REALSENSE": "Synonym for CAP_INTELPERC.",
            "CAP_OPENNI2": "OpenNI2 (for Kinect)",
            "CAP_OPENNI2_ASUS": "OpenNI2 (for Asus Xtion and Occipital Structure sensors)",
            "CAP_OPENNI2_ASTRA": "OpenNI2 (for Orbbec Astra)",
            "CAP_GPHOTO2": "gPhoto2 connection",
            "CAP_GSTREAMER": "GStreamer.",
            "CAP_FFMPEG": "Open and record video file or stream using the FFMPEG library.",
            "CAP_IMAGES": "OpenCV Image Sequence (e.g. img_%02d.jpg)",
            "CAP_ARAVIS": "Aravis SDK.",
            "CAP_OPENCV_MJPEG": "Built-in OpenCV MotionJPEG codec.",
            "CAP_INTEL_MFX": "Intel MediaSDK.",
            "CAP_XINE": "XINE engine (Linux)",
            "CAP_UEYE": "uEye Camera API",
            "CAP_OBSENSOR": "For Orbbec 3D-Sensor device/module (Astra+, Femto)"
        }
    },
    "VideoCaptureProperties": {
        "description": "cv::VideoCapture generic properties identifier.",
        "enumerator": {
            "CAP_PROP_POS_MSEC": "Current position of the video file in milliseconds.",
            "CAP_PROP_POS_FRAMES": "0-based index of the frame to be decoded/captured next.",
            "CAP_PROP_POS_AVI_RATIO": "Relative position of the video file: 0=start of the film, 1=end of the film.",
            "CAP_PROP_FRAME_WIDTH": "Width of the frames in the video stream.",
            "CAP_PROP_FRAME_HEIGHT": "Height of the frames in the video stream.",
            "CAP_PROP_FPS": "Frame rate.",
            "CAP_PROP_FOURCC": "4-character code of codec. see VideoWriter::fourcc .",
            "CAP_PROP_FRAME_COUNT": "Number of frames in the video file.",
            "CAP_PROP_FORMAT": "Format of the Mat objects (see Mat::type()) returned by VideoCapture::retrieve(). Set value -1 to fetch undecoded RAW video streams (as Mat 8UC1).",
            "CAP_PROP_MODE": "Backend-specific value indicating the current capture mode.",
            "CAP_PROP_BRIGHTNESS": "Brightness of the image (only for those cameras that support).",
            "CAP_PROP_CONTRAST": "Contrast of the image (only for cameras).",
            "CAP_PROP_SATURATION": "Saturation of the image (only for cameras).",
            "CAP_PROP_HUE": "Hue of the image (only for cameras).",
            "CAP_PROP_GAIN": "Gain of the image (only for those cameras that support).",
            "CAP_PROP_EXPOSURE": "Exposure (only for those cameras that support).",
            "CAP_PROP_CONVERT_RGB": "Boolean flags indicating whether images should be converted to RGB. \nGStreamer note: The flag is ignored in case if custom pipeline is used. It's user responsibility to interpret pipeline output.",
            "CAP_PROP_WHITE_BALANCE_BLUE_U": "Currently unsupported.",
            "CAP_PROP_RECTIFICATION": "Rectification flag for stereo cameras (note: only supported by DC1394 v 2.x backend currently).",
            "CAP_PROP_MONOCHROME": "",
            "CAP_PROP_SHARPNESS": "",
            "CAP_PROP_AUTO_EXPOSURE": "DC1394: exposure control done by camera, user can adjust reference level using this feature.",
            "CAP_PROP_GAMMA": "",
            "CAP_PROP_TEMPERATURE": "",
            "CAP_PROP_TRIGGER": "",
            "CAP_PROP_TRIGGER_DELAY": "",
            "CAP_PROP_WHITE_BALANCE_RED_V": "",
            "CAP_PROP_ZOOM": "",
            "CAP_PROP_FOCUS": "",
            "CAP_PROP_GUID": "",
            "CAP_PROP_ISO_SPEED": "",
            "CAP_PROP_BACKLIGHT": "",
            "CAP_PROP_PAN": "",
            "CAP_PROP_TILT": "",
            "CAP_PROP_ROLL": "",
            "CAP_PROP_IRIS": "",
            "CAP_PROP_SETTINGS": "Pop up video/camera filter dialog (note: only supported by DSHOW backend currently. The property value is ignored)",
            "CAP_PROP_BUFFERSIZE": "",
            "CAP_PROP_AUTOFOCUS": "",
            "CAP_PROP_SAR_NUM": "Sample aspect ratio: num/den (num)",
            "CAP_PROP_SAR_DEN": "Sample aspect ratio: num/den (den)",
            "CAP_PROP_BACKEND": "Current backend (enum VideoCaptureAPIs). Read-only property.",
            "CAP_PROP_CHANNEL": "Video input or Channel Number (only for those cameras that support)",
            "CAP_PROP_AUTO_WB": "enable/ disable auto white-balance",
            "CAP_PROP_WB_TEMPERATURE": "white-balance color temperature",
            "CAP_PROP_CODEC_PIXEL_FORMAT": "(read-only) codec's pixel format. 4-character code - see VideoWriter::fourcc . Subset of AV_PIX_FMT_* or -1 if unknown",
            "CAP_PROP_BITRATE": "(read-only) Video bitrate in kbits/s",
            "CAP_PROP_ORIENTATION_META": "(read-only) Frame rotation defined by stream meta (applicable for FFmpeg and AVFoundation back-ends only)",
            "CAP_PROP_ORIENTATION_AUTO": "if true - rotates output frames of CvCapture considering video file's metadata (applicable for FFmpeg and AVFoundation back-ends only) (https://github.com/opencv/opencv/issues/15499)",
            "CAP_PROP_HW_ACCELERATION": "(open-only) Hardware acceleration type (see VideoAccelerationType). Setting supported only via params parameter in cv::VideoCapture constructor / .open() method. Default value is backend-specific.",
            "CAP_PROP_HW_DEVICE": "(open-only) Hardware device index (select GPU if multiple available). Device enumeration is acceleration type specific.",
            "CAP_PROP_HW_ACCELERATION_USE_OPENCL": "(open-only) If non-zero, create new OpenCL context and bind it to current thread. The OpenCL context created with Video Acceleration context attached it (if not attached yet) for optimized GPU data copy between HW accelerated decoder and cv::UMat.",
            "CAP_PROP_OPEN_TIMEOUT_MSEC": "(open-only) timeout in milliseconds for opening a video capture (applicable for FFmpeg and GStreamer back-ends only)",
            "CAP_PROP_READ_TIMEOUT_MSEC": "(open-only) timeout in milliseconds for reading from a video capture (applicable for FFmpeg and GStreamer back-ends only)",
            "CAP_PROP_STREAM_OPEN_TIME_USEC": "",
            "CAP_PROP_VIDEO_TOTAL_CHANNELS": "(read-only) Number of video channels",
            "CAP_PROP_VIDEO_STREAM": "(open-only) Specify video stream, 0-based index. Use -1 to disable video stream from file or IP cameras. Default value is 0.",
            "CAP_PROP_AUDIO_STREAM": "(open-only) Specify stream in multi-language media files, -1 - disable audio processing or microphone. Default value is -1.",
            "CAP_PROP_AUDIO_POS": "(read-only) Audio position is measured in samples. Accurate audio sample timestamp of previous grabbed fragment. See CAP_PROP_AUDIO_SAMPLES_PER_SECOND and CAP_PROP_AUDIO_SHIFT_NSEC.",
            "CAP_PROP_AUDIO_SHIFT_NSEC": "(read only) Contains the time difference between the start of the audio stream and the video stream in nanoseconds. Positive value means that audio is started after the first video frame. Negative value means that audio is started before the first video frame.",
            "CAP_PROP_AUDIO_DATA_DEPTH": "(open, read) Alternative definition to bits-per-sample, but with clear handling of 32F / 32S",
            "CAP_PROP_AUDIO_SAMPLES_PER_SECOND": "(open, read) determined from file/codec input. If not specified, then selected audio sample rate is 44100",
            "CAP_PROP_AUDIO_BASE_INDEX": "(read-only) Index of the first audio channel for .retrieve() calls. That audio channel number continues enumeration after video channels.",
            "CAP_PROP_AUDIO_TOTAL_CHANNELS": "(read-only) Number of audio channels in the selected audio stream (mono, stereo, etc)",
            "CAP_PROP_AUDIO_TOTAL_STREAMS": "(read-only) Number of audio streams.",
            "CAP_PROP_AUDIO_SYNCHRONIZE": "(open, read) Enables audio synchronization.",
            "CAP_PROP_LRF_HAS_KEY_FRAME": "FFmpeg back-end only - Indicates whether the Last Raw Frame (LRF), output from VideoCapture::read() when VideoCapture is initialized with VideoCapture::open(CAP_FFMPEG, {CAP_PROP_FORMAT, -1}) or VideoCapture::set(CAP_PROP_FORMAT,-1) is called before the first call to VideoCapture::read(), contains encoded data for a key frame.",
            "CAP_PROP_CODEC_EXTRADATA_INDEX": "Positive index indicates that returning extra data is supported by the video back end. This can be retrieved as cap.retrieve(data, <returned index>). E.g. When reading from a h264 encoded RTSP stream, the FFmpeg backend could return the SPS and/or PPS if available (if sent in reply to a DESCRIBE request), from calls to cap.retrieve(data, <returned index>).",
            "CAP_PROP_FRAME_TYPE": "(read-only) FFmpeg back-end only - Frame type ascii code (73 = 'I', 80 = 'P', 66 = 'B' or 63 = '?' if unknown) of the most recently read frame.",
            "CAP_PROP_N_THREADS": "(open-only) Set the maximum number of threads to use. Use 0 to use as many threads as CPU cores (applicable for FFmpeg back-end only)."
        }
    },
    "VideoWriterProperties": {
        "description": "cv::VideoWriter generic properties identifier.",
        "enumerator": {
            "VIDEOWRITER_PROP_QUALITY": "Current quality (0..100%) of the encoded videostream. Can be adjusted dynamically in some codecs.",
            "VIDEOWRITER_PROP_FRAMEBYTES": "(Read-only): Size of just encoded video frame. Note that the encoding order may be different from representation order.",
            "VIDEOWRITER_PROP_NSTRIPES": "Number of stripes for parallel encoding. -1 for auto detection.",
            "VIDEOWRITER_PROP_IS_COLOR": "If it is not zero, the encoder will expect and encode color frames, otherwise it will work with grayscale frames.",
            "VIDEOWRITER_PROP_DEPTH": "Defaults to CV_8U.",
            "VIDEOWRITER_PROP_HW_ACCELERATION": "(open-only) Hardware acceleration type (see VideoAccelerationType). Setting supported only via params parameter in VideoWriter constructor / .open() method. Default value is backend-specific.",
            "VIDEOWRITER_PROP_HW_DEVICE": "(open-only) Hardware device index (select GPU if multiple available). Device enumeration is acceleration type specific.",
            "VIDEOWRITER_PROP_HW_ACCELERATION_USE_OPENCL": "(open-only) If non-zero, create new OpenCL context and bind it to current thread. The OpenCL context created with Video Acceleration context attached it (if not attached yet) for optimized GPU data copy between cv::UMat and HW accelerated encoder."
        }
    }
}